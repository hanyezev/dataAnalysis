{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T02:26:54.080437Z",
     "start_time": "2020-11-26T02:26:52.834001Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np;\n",
    "import importlib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T02:26:54.774639Z",
     "start_time": "2020-11-26T02:26:54.083435Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T02:26:54.798643Z",
     "start_time": "2020-11-26T02:26:54.776642Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def evaluate(data, X, Y, model, evaluateL2, evaluateL1, batch_size):\n",
    "    model.eval();\n",
    "    total_loss = 0;\n",
    "    total_loss_l1 = 0;\n",
    "    n_samples = 0;\n",
    "    predict = None;\n",
    "    test = None;\n",
    "    \n",
    "    for X, Y in data.get_batches(X, Y, batch_size, False):\n",
    "        output = model(X);\n",
    "        if predict is None:\n",
    "            predict = output;\n",
    "            test = Y;\n",
    "        else:\n",
    "            predict = torch.cat((predict,output));\n",
    "            test = torch.cat((test, Y));\n",
    "        \n",
    "        scale = data.scale.expand(output.size(0), data.m)\n",
    "        total_loss += evaluateL2(output * scale, Y * scale).data[0]\n",
    "        total_loss_l1 += evaluateL1(output * scale, Y * scale).data[0]\n",
    "        n_samples += (output.size(0) * data.m);\n",
    "    rse = math.sqrt(total_loss / n_samples)/data.rse\n",
    "    rae = (total_loss_l1/n_samples)/data.rae\n",
    "    \n",
    "    predict = predict.data.cpu().numpy();\n",
    "    Ytest = test.data.cpu().numpy();\n",
    "    sigma_p = (predict).std(axis = 0);\n",
    "    sigma_g = (Ytest).std(axis = 0);\n",
    "    mean_p = predict.mean(axis = 0)\n",
    "    mean_g = Ytest.mean(axis = 0)\n",
    "    index = (sigma_g!=0);\n",
    "    correlation = ((predict - mean_p) * (Ytest - mean_g)).mean(axis = 0)/(sigma_p * sigma_g);\n",
    "    correlation = (correlation[index]).mean();\n",
    "    return rse, rae, correlation;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T02:26:54.809644Z",
     "start_time": "2020-11-26T02:26:54.801644Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train(data, X, Y, model, criterion, optim, batch_size):\n",
    "    model.train();\n",
    "    total_loss = 0;\n",
    "    n_samples = 0;\n",
    "    for X, Y in data.get_batches(X, Y, batch_size, True):\n",
    "        model.zero_grad();\n",
    "        output = model(X);\n",
    "        scale = data.scale.expand(output.size(0), data.m)\n",
    "        loss = criterion(output * scale, Y * scale);\n",
    "        loss.backward();\n",
    "        grad_norm = optim.step();\n",
    "        total_loss += loss.data[0];\n",
    "        n_samples += (output.size(0) * data.m);\n",
    "    return total_loss / n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T02:47:09.606249Z",
     "start_time": "2020-11-26T02:47:09.571248Z"
    },
    "code_folding": [
     0,
     3
    ]
   },
   "outputs": [],
   "source": [
    "def normal_std(x):\n",
    "    return x.std() * np.sqrt((len(x) - 1.)/(len(x)))\n",
    "\n",
    "class Data_utility(object):\n",
    "    # train and valid is the ratio of training set and validation set. test = 1 - train - valid\n",
    "    def __init__(self, file_name, train, valid, cuda, horizon, window, normalize = 2):\n",
    "        self.cuda = cuda;\n",
    "        self.P = window;\n",
    "        self.h = horizon\n",
    "        fin = open(file_name);\n",
    "        self.rawdat = np.loadtxt(fin,delimiter=';',skiprows=0);\n",
    "        self.dat = np.zeros(self.rawdat.shape);\n",
    "        self.n, self.m = self.dat.shape;\n",
    "        self.normalize = 2\n",
    "        self.scale = np.ones(self.m);\n",
    "        self._normalized(normalize);\n",
    "        self._split(int(train * self.n), int((train+valid) * self.n), self.n);\n",
    "        \n",
    "        self.scale = torch.from_numpy(self.scale).float();\n",
    "        tmp = self.test[1] * self.scale.expand(self.test[1].size(0), self.m);\n",
    "            \n",
    "        if self.cuda:\n",
    "            self.scale = self.scale.cuda();\n",
    "        self.scale = Variable(self.scale);\n",
    "        \n",
    "        self.rse = normal_std(tmp);\n",
    "        self.rae = torch.mean(torch.abs(tmp - torch.mean(tmp)));\n",
    "    \n",
    "    def _normalized(self, normalize):\n",
    "        #normalized by the maximum value of entire matrix.\n",
    "       \n",
    "        if (normalize == 0):\n",
    "            self.dat = self.rawdat\n",
    "            \n",
    "        if (normalize == 1):\n",
    "            self.dat = self.rawdat / np.max(self.rawdat);\n",
    "            \n",
    "        #normlized by the maximum value of each row(sensor).\n",
    "        if (normalize == 2):\n",
    "            for i in range(self.m):\n",
    "                self.scale[i] = np.max(np.abs(self.rawdat[:,i]));\n",
    "                self.dat[:,i] = self.rawdat[:,i] / np.max(np.abs(self.rawdat[:,i]));\n",
    "            \n",
    "        \n",
    "    def _split(self, train, valid, test):\n",
    "        \n",
    "        train_set = range(self.P+self.h-1, train);\n",
    "        valid_set = range(train, valid);\n",
    "        test_set = range(valid, self.n);\n",
    "        self.train = self._batchify(train_set, self.h);\n",
    "        self.valid = self._batchify(valid_set, self.h);\n",
    "        self.test = self._batchify(test_set, self.h);\n",
    "        \n",
    "        \n",
    "    def _batchify(self, idx_set, horizon):\n",
    "        \n",
    "        n = len(idx_set);\n",
    "        X = torch.zeros((n,self.P,self.m));\n",
    "        Y = torch.zeros((n,self.m));\n",
    "        \n",
    "        for i in range(n):\n",
    "            end = idx_set[i] - self.h + 1;\n",
    "            start = end - self.P;\n",
    "            X[i,:,:] = torch.from_numpy(self.dat[start:end, :]);\n",
    "            Y[i,:] = torch.from_numpy(self.dat[idx_set[i], :]);\n",
    "\n",
    "        return [X, Y];\n",
    "\n",
    "    def get_batches(self, inputs, targets, batch_size, shuffle=True):\n",
    "        length = len(inputs)\n",
    "        if shuffle:\n",
    "            index = torch.randperm(length)\n",
    "        else:\n",
    "            index = torch.LongTensor(range(length))\n",
    "        start_idx = 0\n",
    "        while (start_idx < length):\n",
    "            end_idx = min(length, start_idx + batch_size)\n",
    "            excerpt = index[start_idx:end_idx]\n",
    "            X = inputs[excerpt]; Y = targets[excerpt];\n",
    "            if (self.cuda):\n",
    "                X = X.cuda();\n",
    "                Y = Y.cuda();  \n",
    "            yield Variable(X), Variable(Y);\n",
    "            start_idx += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T03:08:34.508134Z",
     "start_time": "2020-11-26T03:08:34.484132Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, cuda, window, hidRNN, hidCNN,CNN_kernel, hidSkip,skip,highway_window,dropout,output_fun,data):\n",
    "        super(Model, self).__init__()\n",
    "        self.use_cuda = cuda\n",
    "        self.P = window;\n",
    "        self.m = data.m\n",
    "        self.hidR = hidRNN;\n",
    "        self.hidC = hidCNN;\n",
    "        self.hidS = hidSkip;\n",
    "        self.Ck = CNN_kernel;\n",
    "        self.skip = skip;\n",
    "        self.pt = (self.P - self.Ck)/self.skip\n",
    "        self.hw = highway_window\n",
    "        self.conv1 = nn.Conv2d(1, self.hidC, kernel_size = (self.Ck, self.m));\n",
    "        self.GRU1 = nn.GRU(self.hidC, self.hidR);\n",
    "        self.dropout = nn.Dropout(p = dropout);\n",
    "        if (self.skip > 0):\n",
    "            self.GRUskip = nn.GRU(self.hidC, self.hidS);\n",
    "            self.linear1 = nn.Linear(self.hidR + self.skip * self.hidS, self.m);\n",
    "        else:\n",
    "            self.linear1 = nn.Linear(self.hidR, self.m);\n",
    "        if (self.hw > 0):\n",
    "            self.highway = nn.Linear(self.hw, 1);\n",
    "        self.output = None;\n",
    "        if (output_fun == 'sigmoid'):\n",
    "            self.output = F.sigmoid;\n",
    "        if (output_fun == 'tanh'):\n",
    "            self.output = F.tanh;\n",
    " \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0);\n",
    "        \n",
    "        #CNN\n",
    "        c = x.view(-1, 1, self.P, self.m);\n",
    "        c = F.relu(self.conv1(c));\n",
    "        c = self.dropout(c);\n",
    "        c = torch.squeeze(c, 3);\n",
    "        \n",
    "        # RNN \n",
    "        r = c.permute(2, 0, 1).contiguous();\n",
    "        _, r = self.GRU1(r);\n",
    "        r = self.dropout(torch.squeeze(r,0));\n",
    "\n",
    "        \n",
    "        #skip-rnn\n",
    "        \n",
    "        if (self.skip > 0):\n",
    "            s = c[:,:, int(-self.pt * self.skip):].contiguous();\n",
    "            s = s.view(batch_size, self.hidC, self.pt, self.skip);\n",
    "            s = s.permute(2,0,3,1).contiguous();\n",
    "            s = s.view(self.pt, batch_size * self.skip, self.hidC);\n",
    "            _, s = self.GRUskip(s);\n",
    "            s = s.view(batch_size, self.skip * self.hidS);\n",
    "            s = self.dropout(s);\n",
    "            r = torch.cat((r,s),1);\n",
    "        \n",
    "        res = self.linear1(r);\n",
    "        \n",
    "        #highway\n",
    "        if (self.hw > 0):\n",
    "            z = x[:, -self.hw:, :];\n",
    "            z = z.permute(0,2,1).contiguous().view(-1, self.hw);\n",
    "            z = self.highway(z);\n",
    "            z = z.view(-1,self.m);\n",
    "            res = res + z;\n",
    "            \n",
    "        if (self.output):\n",
    "            res = self.output(res);\n",
    "        return res;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T02:26:54.892651Z",
     "start_time": "2020-11-26T02:26:54.875648Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Optim(object):\n",
    "\n",
    "    def _makeOptimizer(self):\n",
    "        if self.method == 'sgd':\n",
    "            self.optimizer = optim.SGD(self.params, lr=self.lr)\n",
    "        elif self.method == 'adagrad':\n",
    "            self.optimizer = optim.Adagrad(self.params, lr=self.lr)\n",
    "        elif self.method == 'adadelta':\n",
    "            self.optimizer = optim.Adadelta(self.params, lr=self.lr)\n",
    "        elif self.method == 'adam':\n",
    "            self.optimizer = optim.Adam(self.params, lr=self.lr)\n",
    "        else:\n",
    "            raise RuntimeError(\"Invalid optim method: \" + self.method)\n",
    "\n",
    "    def __init__(self, params, method, lr, max_grad_norm, lr_decay=1, start_decay_at=None):\n",
    "        self.params = list(params)  # careful: params may be a generator\n",
    "        self.last_ppl = None\n",
    "        self.lr = lr\n",
    "        self.max_grad_norm = max_grad_norm\n",
    "        self.method = method\n",
    "        self.lr_decay = lr_decay\n",
    "        self.start_decay_at = start_decay_at\n",
    "        self.start_decay = False\n",
    "\n",
    "        self._makeOptimizer()\n",
    "\n",
    "    def step(self):\n",
    "        # Compute gradients norm.\n",
    "        grad_norm = 0\n",
    "        for param in self.params:\n",
    "            grad_norm += math.pow(param.grad.data.norm(), 2)\n",
    "\n",
    "        grad_norm = math.sqrt(grad_norm)\n",
    "        if grad_norm > 0:\n",
    "            shrinkage = self.max_grad_norm / grad_norm\n",
    "        else:\n",
    "            shrinkage = 1.\n",
    "\n",
    "        for param in self.params:\n",
    "            if shrinkage < 1:\n",
    "                param.grad.data.mul_(shrinkage)\n",
    "\n",
    "        self.optimizer.step()\n",
    "        return grad_norm\n",
    "\n",
    "    # decay learning rate if val perf does not improve or we hit the start_decay_at limit\n",
    "    def updateLearningRate(self, ppl, epoch):\n",
    "        if self.start_decay_at is not None and epoch >= self.start_decay_at:\n",
    "            self.start_decay = True\n",
    "        if self.last_ppl is not None and ppl > self.last_ppl:\n",
    "            self.start_decay = True\n",
    "\n",
    "        if self.start_decay:\n",
    "            self.lr = self.lr * self.lr_decay\n",
    "            print(\"Decaying learning rate to %g\" % self.lr)\n",
    "        #only decay for one epoch\n",
    "        self.start_decay = False\n",
    "\n",
    "        self.last_ppl = ppl\n",
    "\n",
    "        self._makeOptimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T02:26:54.906653Z",
     "start_time": "2020-11-26T02:26:54.895651Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser(description='PyTorch Time series forecasting')\n",
    "# parser.add_argument('--data', type=str, required=True, help='location of the data file')\n",
    "data = r\"F:\\python数据\\LD2011_2014\\LD2011_2014.txt\"\n",
    "# parser.add_argument('--model', type=str, default='LSTNet',help='')\n",
    "model = \"LSTNet\"\n",
    "# parser.add_argument('--hidCNN', type=int, default=100, help='number of CNN hidden units')\n",
    "hidCNN = 100                  \n",
    "# parser.add_argument('--hidRNN', type=int, default=100, help='number of RNN hidden units')\n",
    "hidRNN =100\n",
    "# parser.add_argument('--window', type=int, default=24 * 7, help='window size')\n",
    "window = 24 * 7\n",
    "# parser.add_argument('--CNN_kernel', type=int, default=6,help='the kernel size of the CNN layers')\n",
    "CNN_kernel = 6\n",
    "# parser.add_argument('--highway_window', type=int, default=24,help='The window size of the highway component')\n",
    "highway_window = 24\n",
    "# parser.add_argument('--clip', type=float, default=10.,help='gradient clipping')\n",
    "clip = 10\n",
    "# parser.add_argument('--epochs', type=int, default=100,help='upper epoch limit')\n",
    "epochs = 100\n",
    "# parser.add_argument('--batch_size', type=int, default=128, metavar='N',help='batch size')\n",
    "batch_size = 128\n",
    "# parser.add_argument('--dropout', type=float, default=0.2,help='dropout applied to layers (0 = no dropout)')\n",
    "dropout = 0.2\n",
    "# parser.add_argument('--seed', type=int, default=54321,help='random seed')\n",
    "seed = 54321\n",
    "# parser.add_argument('--gpu', type=int, default=None)\n",
    "gpu =None\n",
    "# parser.add_argument('--log_interval', type=int, default=2000, metavar='N', help='report interval')\n",
    "log_interval = 2000\n",
    "# parser.add_argument('--save', type=str,  default='model/model.pt', help='path to save the final model')\n",
    "save = 'model/model.pt'\n",
    "# parser.add_argument('--cuda', type=str, default=True)\n",
    "cuda = False\n",
    "# parser.add_argument('--optim', type=str, default='adam')\n",
    "optim = \"adam\"\n",
    "# parser.add_argument('--lr', type=float, default=0.001)\n",
    "lr = 0.001\n",
    "# parser.add_argument('--horizon', type=int, default=12)\n",
    "horizon = 12\n",
    "# parser.add_argument('--skip', type=float, default=24)\n",
    "skip = 24\n",
    "# parser.add_argument('--hidSkip', type=int, default=5)\n",
    "hidSkip = 5\n",
    "# parser.add_argument('--L1Loss', type=bool, default=True)\n",
    "L1Loss = True\n",
    "# parser.add_argument('--normalize', type=int, default=2)\n",
    "normalize = 2\n",
    "# parser.add_argument('--output_fun', type=str, default='sigmoid')\n",
    "output_fun = \"sigmoid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T02:26:54.930654Z",
     "start_time": "2020-11-26T02:26:54.909653Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x292a8281670>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T03:16:51.553919Z",
     "start_time": "2020-11-26T03:16:40.026944Z"
    }
   },
   "outputs": [],
   "source": [
    "Data = pd.read_csv(r\"F:\\python数据\\LD2011_2014\\LD2011_2014.txt\",sep=\";\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T03:16:51.582923Z",
     "start_time": "2020-11-26T03:16:51.556921Z"
    }
   },
   "outputs": [],
   "source": [
    "datas = (Data[[\"MT_002\",\"MT_003\",\"MT_004\",\"MT_005\"]].values)[40000:45000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T03:16:51.604924Z",
     "start_time": "2020-11-26T03:16:51.587922Z"
    }
   },
   "outputs": [],
   "source": [
    "f = open(r\"F:\\python数据\\LD2011_2014\\data.txt\",\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T03:16:51.663929Z",
     "start_time": "2020-11-26T03:16:51.610925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sucess\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(datas)):\n",
    "    f.write(str(datas[i][0]) + \";\"+ str(datas[i][1])+ \";\"+ str(datas[i][2])+ \";\"+ str(datas[i][3]))\n",
    "    f.write('\\n')\n",
    "f.close()\n",
    "print(\"sucess\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T03:16:51.698931Z",
     "start_time": "2020-11-26T03:16:51.667930Z"
    }
   },
   "outputs": [],
   "source": [
    "# 去除逗号\n",
    "import re\n",
    "with open(r\"F:\\python数据\\LD2011_2014\\data.txt\") as txtData:\n",
    "    lines = txtData.read()\n",
    "    pat = re.compile(\",\")\n",
    "    a = pat.sub(\"\", lines)\n",
    "    fw = open(r\"F:\\python数据\\LD2011_2014\\data2.txt\",\"w\")\n",
    "    fw.write(a)\n",
    "    fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T03:16:51.708933Z",
     "start_time": "2020-11-26T03:16:51.702931Z"
    }
   },
   "outputs": [],
   "source": [
    "file_data  = r\"F:\\python数据\\LD2011_2014\\data2.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T03:16:52.618085Z",
     "start_time": "2020-11-26T03:16:51.715936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4992e+14)\n"
     ]
    }
   ],
   "source": [
    "Data = Data_utility(file_data, 0.6, 0.2, False, horizon, window, normalize)\n",
    "print(Data.rse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T03:16:52.632087Z",
     "start_time": "2020-11-26T03:16:52.622087Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Model(cuda=cuda, window=window, hidRNN=hidRNN, hidCNN=hidCNN, hidSkip=hidSkip,\n",
    "                          CNN_kernel=CNN_kernel,skip=skip, highway_window=highway_window, dropout=dropout,output_fun=output_fun,data=Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T03:15:34.916964Z",
     "start_time": "2020-11-26T03:15:34.889960Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'Adam'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-515ef49bfe4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbest_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10000000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m optim = Optim(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m )\n",
      "\u001b[1;32m<ipython-input-7-09a2ef65a1ad>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, method, lr, max_grad_norm, lr_decay, start_decay_at)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_decay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_makeOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-09a2ef65a1ad>\u001b[0m in \u001b[0;36m_makeOptimizer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdadelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'adam'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid optim method: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'Adam'"
     ]
    }
   ],
   "source": [
    "best_val = 10000000\n",
    "optim = Optim(\n",
    "    model.parameters(), optim, lr, clip,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "env_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
